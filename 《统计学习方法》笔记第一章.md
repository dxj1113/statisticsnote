# 李航《统计学习方法》学习笔记
## 第一章《统计学习方法概论》
###  统计学习
**统计学习的概念**：

计算机基于数据构建统计模型并运用模型对数据进行预测与分析的一门学科

**统计学习的特点**

* 统计学习以计算机和网络为平台。
* 统计学习以数据为研究对象，是数据驱动的学科。
* 统计学习的目的是对数据进行分析和预测。
* 统计学习以方法为核心，构建模型并应用模型对数据进行分析预测。
* 统计学习是概率论、统计学、信息论、计算理论、最优化理论及计算机科学多个领域的交叉学科。

**统计学习的对象**

* 数据，包括数字，文字，图像，视频，音频，以及他们的组合。
* 统计学习的前提是数据有统计规律性。

**统计学习的目的**

对未知数据进行预测和分析

**统计学习的方法**

* 监督学习
* 非监督学习
* 半监督学习
* 强化学习

**统计学习三要素**

* 模型
* 策略
* 算法

**统计学习的步骤**

1. 得到一个有限的训练数据的集合
2. 确定包含所有可能的模型的假设空间，即学习模型的集合
3. 确定模型学习的准则，即学习的策略。
4. 实现求解最优模型的算法，即学习的算法。
5. 通过学习方法选择最优算法
6. 利用学习的最优模型对新数据进行预测或分析

**统计学习的研究**

* 统计学习方法
* 统计学习理论
* 统计学习应用

### 监督学习
####概念：
学习一个模型，使模型能够对任意给定的输入，对其对应的输出做出一个好的预测。

监督学习的基本概念

* 输入空间
* 输出空间
* 特征空间
　

输入变量的特征空间
$x=(x^1,x^2,x^3.......x^n)^T$
上标表示特征向量，下标表示输入变量中的第N个
$X_i=(X_i^1,X_i^2,X_i^3.....X_i^n)^T$
训练数据由输入输出对组成
$T={(X_1,Y_1),(X_2,Y_2),(X_3,Y_3)......(X_n,Y_n)}$

联合概率分布
监督学习假设输入与输出的随机变量X和Y遵循联合概率分布$P(X,Y)$

假设空间
监督学习的目的在于学习一个由输入到输出的映射，这一映射由模型来表示。
监督学习的模型可以是概率模型或非概率模型，由条件概率分布$P(Y|X)$或决策函数$Y=f(X)$表示。

#### 问题的形式化


```flow
st1=>start: 
st2=>start2: 
op1=>operation: 数据
op2=>operation: 训练系统
op3=>operation: 预测系统
op4=>operation: 模型
cond1=>condition: 训练or预测?

st1->op1->cond1
cond1(yes)->op2
cond1(no)->op3
op2->op4
op4->op3
```
### 统计学习三要素
方法=模型+策略+算法

#### 模型
假设空间
$F=\{f|Y=f(X)\}$
X,Y是定义在输入空间X和输出空间Y上的变量。这时F通常是由一个参数向量决定的函数族
$F=\{f|Y=f_\theta(X),\theta\in R^n\}$
参数向量$\theta$取决于n维欧式空间$R^n$,称为参数空间。

假设空间也可以定义为条件概率的集合
$F=\{p|p(Y|X)\}$
其中，X和Y是定义在输入空间X和输出空间Y上的变量。这时F通常是由一个参数向量决定的条件概率分布族。
$F=\{P|P_\theta(Y|X),\theta\in R^n\}$

#### 策略

##### 损失函数和风险函数

* 0-1损失函数
$L(Y,f(X))=
\begin{bmatrix}
 1,Y\neq f(x) \\
 0,Y\neq f(x)
\end{bmatrix}$
* 平方损失函数
  $L(Y,f(X))=(Y-f(X))^2$
* 绝对损失函数
  $L(Y,f(X))=|Y-f(X)|$
* 对数损失函数
  $L(Y,P(Y|X))=-log P(Y|X)$ 

损失函数的数学期望
$R_{exp}=EP[L(Y,f(X))]=\int_{XY}L(Y,f(X))P(x,y)dx dy$

给定数据集
$$T=\{(X_1,Y_1),(X_2,Y_2),(X_3,Y_3).....(X_N,Y_N)\}$$

模型$f(X)$关于训练数据集的平均损失称为经验风险或经验损失
$$R_{emp}(f)=\frac 1N \sum_1^N L(y_i,f(x_i)) $$

##### 经验风险最小化和结构风险最小化
 在假设空间、损失函数及训练数据确定的情况下，经验风险函数式可以确定。经验风险最小化的策略认为，经验风险最小的模型是最优的模型。
 $$min_{f\in F}\frac 1N  \sum_1^N L(y_i,f(x_i))$$
 
 结构风险最小化是为了防止过拟合而提出的策略，在经验风险上加上表示模型复杂度的正则化项或者罚项。
 
 $$R_{srm}(f)=\frac 1N \sum_1^N L(y_i,f(x_i))+ \lambda J(f)$$
 其中J(f)为模型的复杂度，是定义在假设空间F上的[泛函](http://baike.baidu.com/link?url=9-bu0EtcyWhE70AjaGMAkJuZz8EZ0A-JHl8twl_DFaHivELdFN8qYIFCZf2LYHdotAXYAcrZNQaWwqX27YSrEyoR0Cs2obSs4yje64KV5r3)。
结构风险最小化的定义
$$min_{f\in F}\frac 1N \sum_1^N L(y_i,f(x_i))+ \lambda J(f)$$

#### 算法
算法：学习模型的具体计算方法。
统计学习问题归结为最优化问题，统计学习的算法称为求解最优化问题的算法。

### 模型评估与模型选择
#### 训练误差与测试误差
训练误差公式(样本容量为N)
$$R_{emp}(f)=\frac 1N \sum_1^N L(y_i,f(x_i))$$

测试误差公式(测试样本容量为N)
$$e_{test}=\frac 1N \sum_1^N L(y_i,f(x_i))$$

当损失函数式0-1损失时，测试误差
$$e_{test}=\frac 1N \sum_1^N I(y_i\neq f(x_i))$$

测试数据集的准确率
$$r_{test}=\frac 1N \sum_1^N I(y_i= f(x_i))$$

$$e_{test}+r_{test}=1$$

#### 过拟合和模型选择
假设一个给定的数据集
$$$T=\{(X_1,Y_1),(X_1,Y_1),(X_1,Y_1).....(X_n,Y_n),\}$$
其中$x_i\in R$是输入的观测值。$y_i\in R$是输出观测值。
设M多项式为
$$f_M(x,w)=w_0+w_1x+w_2x^2_....+w_mx^m=\sum_{j=0}^Nw_jx^j$$

解决问题的办法：确定复杂度（多项式次数），然后在给定的模型复杂度下，按照经验风险最小化的策略，求解参数。最小化下列公式
$$L(w)=\frac 12\sum_{i=1}^N(f(x_i,w)-y_i)$$
上述两公式合并可得
$$L(w)=\frac 12\sum_{i=1}^N(\sum_{j=0}^Nw_jx^j-y_i)$$
可用[最小二乘法](http://baike.baidu.com/link?url=OXhft7nFtSAJ0cTPjXRUXRCs2J5N96qI_7CwBqjsrPVSQoRznWuUfRKaKVZTxICVGaHA9u2jzgmF-78X0evaaqRCgezzig2sznpuvWyZ4x9UIg20AkYf0rfhABiXGE_N-TxflbHSgFirmSlGp87_g_)求的唯一解.

### 正则化和交叉验证
正则化的概念：结构风险最小化的实现，在经验风险上加上一个正则化项或罚项。
$$min_{f\in F}\frac 1N\sum_{i=1}^NL(Y_i,f(x_i))+\lambda J(f)$$

回归问题的正则化项
$$L(w)=\frac 1N\sum_{i=1}^NL(f(x_i;w)-y_i)^2+\frac\lambda 2 ||w||^2$$

$||w||$表示参数向量w的$L^2$[范数](https://www.baidu.com/link?url=vmcP2vG6yGxk7Zg0TwxI7xfb1vaEHgUTX5hW0ro3qRZuUj892iIrjmgA0bYa4vZ1xvtswZJCFnSsos0EDWXiKK0UqmgtWTpUW19I0kTf_yK&wd=&eqid=e9b0e5eb0002b98e00000006587b9345)

正则化项也可以是参数向量的L1范数
$$L(w)=\frac 1N\sum_{i=1}^NL(f(x_i;w)-y_i)^2+\lambda ||w||_1$$

#### 交叉验证

* 简单交叉验证（例如70%为训练集，30%为测试集）
* S折交叉验证（留出S个子集，用S-1的子集用作训练，剩下的子集用作测试，反复进行）
* 留一交叉验证（S折交叉验证的特殊情况）

### 泛化能力
泛化能力的概念：指学习到的模型对未知数据的预测能力。
$$R_{exp}(f)=E_p[L(Y,f(X))]=\int_{XY}L(y,f(x))p(x,y)dxdy$$

泛化误差上届
基本假设
训练数据集$T=\{(x_1,y_1),(x_2,y_2),(x_3,y_3).....(x_N,y_N) \}$
从联合概率分布$P(X,Y)$独立分布产生。
$X\in R^N$,$Y\in \{-1,+1\}$
假设空间$F=\{f_1,f_2,f_3......f_d \}$,d是函数个数。f是F中选取得函数，损失函数式0-1损失。
期望风险
$$R(f)=E[L(Y,f(X))]$$
经验风险
$$R^1(f)=\frac 1N \sum_{i=1}^NL(Y_i,f(x_i))$$
经验风险最小化函数
$$f_N=arg min_{f\in F}R(f)$$
$f_N$的泛化能力
$$R(f_N)=E[l(Y,f_N(X))]$$

**定理1.1 泛化误差上届**
$$R(f)\leqslant R^1(f)+\epsilon (d,N,\delta)$$
其中
$$\epsilon (d,N,\delta)=\sqrt{\frac 1{2N}(log d+log \frac1{\delta})}$$

证明略
### 生成模型和判别模型
* 生成方法由数据学习联合概率分布$P(X,Y)$,然后求出条件概率
  $P(Y|X)=\frac {P(X,Y)}{P(X)}$
  特点:还原联合概率分布,收敛速度快，可以在存在隐变量的情况下学习
* 判别方法由数据直接学习决策函数$f(x)$或者$P(Y|X)$作为判别模型。 特点：直接面对预测，准确率高。

### 分类问题
监督学习中，输出变量Y为有限个离散值时，预测问题便成为分类问题。
二分类问题的评价指标
TP--将正类预测成正类
FN--将正类预测成负类
FP--将负类预测成正类
TN--将负类预测成负类

精确率定义$P=\frac {TP}{TP+FP}$
召回率定义$R=\frac {TP}{TP+FN}$
$F_1$值
$$\frac 2F_1=\frac 1P+\frac 1R$$
$$F_1=\frac {2TP}{2TP+FP+FN}$$

### 标注问题
概念：输入一个观测序列，输出一个标记序列或状态序列。
给定训练集
$T=\{(x_1,y_1),(x_2,y_2),(x_3,y_3).....(x_N,y_N) \}$
构建一个模型
$$P(Y^{(1)},Y^{(2)},Y^{(3)}....Y^{(n)}|X^{(1)},X^{(2)},X^{(3)}....X^{(n)})$$
标注系统按照学习到的概率模型，对新的输入观测序列找到对应的输出标记序列。

常用的标注统计学习方法：[隐马尔科夫模型](http://www.cnblogs.com/skyme/p/4651331.html)、[条件随机场](https://www.zhihu.com/question/35866596)
标注问题的应用领域：[自然语言处理](http://baike.baidu.com/link?url=MSezbSKMVL1Jdgpcjz_WSSQJCBYciwCXCw6AspjwQGrzWEMKvSxbEaHh7gYrNiuLFjy5SGYyvcy3tIRzKA9tyDzxooXUO5TtdGrzii2Gp6EQd0p1q7tGSUfprUAwXjZqYyxNfa0VcvBjGM6v8Lzz1q)、[信息抽取](http://baike.baidu.com/link?url=gvxwuRixR2z6iHraVHCnHWsnHmZl8_ZbePoqLoPsRZ3Yfu-iApqpzaFLnxRYHnGCitOaWB0aXwRcwQch3kuDz25RZhLTJzC6M8iO6T99P1KIkYEZjktLWTClViBf8pVi)

### 回归问题
概念：预测输入变量与输出变量之间的关系。
给定训练集
$T=\{(x_1,y_1),(x_2,y_2),(x_3,y_3).....(x_N,y_N) \}$
构建函数$y=f(x)$使得对于新的输入$X_{N+1}$,根据模型输出$Y_{N+1}$
根据输入变量的个数，可分为一元回归和多元回归。按照输入输出变量之间的关系，可分为线性回归和非线性回归。
损失函数：平方损失函数。

### 本章概要
1.统计学习是关于计算机基于数据构建概率统计模型并运用模型对数据进行分析和预测的一门学科。统计学习包括监督学习，非监督学习，半监督学习和强化学习。
2.统计学习方法三要素-模型、策略、算法。
3.本书主要讨论监督学习，监督学习可以概括如下：从给定有限的训练数据出发，假设数据是独立同分布的，而且假设模型属于某个假设空间，应用某一评价准则，从假设空间中选取一个最优的模型，使得它对已给数据及未知测试数据在给定评价标准意义下有最准确的预测。
4.统计学习中，进行模型选择或者说提高学习的泛化能力是一个重要问题。如果只考虑减训练误差，可能产生过拟合。模型的选择方法有正则化和交叉验证。学习方法泛化能力的分析是统计学习理论研究的重要课题。
5.分类问题、标注问题和回归问题都是监督学习的重要课题。本书中介绍的统计学习方法包括感知机、K近邻法、朴素贝叶斯法、决策树，逻辑斯蒂回归与最大熵模型、支持向量机、提升方法、EM算法、隐马尔科夫模型和条件随机场。